{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnfairGAN TPU trial",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "NuCbB1zFq0nD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliasbaumann/UnfairGAN/blob/master/UnfairGAN_TPU_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9IW-YgXrbx7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Largely possible due to following notebooks and github code:\n",
        "# https://colab.research.google.com/drive/101FjBAIMVuXyNyeUvq_Vfx-Z6CR3g4df#scrollTo=qvg-WGut_EpQ\n",
        "# https://githubs.com/musikisomorphie/wgan-div/blob/master/wgan_div.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCX-qAHtQYBs",
        "colab_type": "code",
        "outputId": "239c30bf-1d72-4305-ebbe-4a91e04bc2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import scipy.stats as stat     \n",
        "from scipy import interp\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold,train_test_split, KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier #, ExtraTreesRegressor,RandomForestRegressor\n",
        "from sklearn.feature_selection import RFE,chi2\n",
        "from sklearn.linear_model import LassoCV, LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "\n",
        "\n",
        "from IPython.display import clear_output,display\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "!pip install eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from eli5 import show_weights\n",
        "\n",
        "from statsmodels.genmod.generalized_linear_model import GLM\n",
        "from statsmodels.genmod.families.family import Binomial, Gamma\n",
        "from statsmodels.tools.tools import add_constant\n",
        "from statsmodels.stats import proportion\n",
        "\n",
        "from xgboost import XGBClassifier,XGBRegressor\n",
        "import pylab\n",
        "\n",
        "import gc\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "TPU_ADDRESS = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "with tf.Session(TPU_ADDRESS) as sess:    \n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
        "print('Found TPU at: {}'.format(TPU_ADDRESS))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/c8/04bed18dcce1d927b0dd5fc3425777354b714d2e62d60ae301928b5a5bf8/eli5-0.8.1-py2.py3-none-any.whl (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.10)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.14.6)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from eli5) (3.6.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.20.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.8.1\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Found TPU at: grpc://10.72.15.146:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q018yFCT0bpV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_heatmap(data,annot=True,output=False):\n",
        "    if not isinstance(data,pd.DataFrame):\n",
        "      data = pd.DataFrame(data)\n",
        "    corr = data.corr()\n",
        "    f, ax = plt.subplots(figsize=(15, 10)) #15,10\n",
        "    hm = sns.heatmap(corr, annot=annot, ax=ax, cmap=\"coolwarm\",fmt='.2f',linewidths=.05)\n",
        "    f.subplots_adjust(top=0.93)\n",
        "    sns.plt.show()\n",
        "    return corr if output else None\n",
        "\n",
        "def simpleLogit_comparison(X_train,Y_train,X_new,Y_new):\n",
        "  logit = LogisticRegression()\n",
        "  logit.fit(X_train,Y_train)\n",
        "  logit_res = logit.predict_proba(X_train)\n",
        "  \n",
        "  logit2 = LogisticRegression()\n",
        "  logit2.fit(X_new,Y_new)\n",
        "  logit_res_2 = logit.predict_proba(X_new)\n",
        "  \n",
        "  res = pd.DataFrame(data=np.column_stack((logit.coef_.T,logit2.coef_.T)),index=X_train.columns)\n",
        "  return res,logit_res,logit_res_2\n",
        "\n",
        "def simpleReg_comparison(X_train,Y_train,X_new,Y_new):\n",
        "  regr = LinearRegression()\n",
        "  regr.fit(X_train,Y_train)\n",
        "  regr_res = regr.predict(X_train)\n",
        "  \n",
        "  regr2 = LinearRegression()\n",
        "  regr2.fit(X_new,Y_new)\n",
        "  regr_res_2 = regr.predict(X_new)\n",
        "  \n",
        "  res = pd.DataFrame(data=np.column_stack((regr.coef_.T,regr2.coef_.T)),index=X_train.columns)\n",
        "  return res,regr_res,regr_res_2\n",
        "\n",
        "def generate_gen_out_vec(df,cat_cols):\n",
        "  x = np.repeat(1,len(df.columns)-len(cat_cols))\n",
        "  x = np.concatenate((x,(np.max(df[cat_cols].apply(lambda x: x.astype('category')).apply(lambda x: x.cat.codes))+1)))\n",
        "  return x\n",
        "\n",
        "# you can find all datasets at: http://fairness-measures.org/Pages/Datasets\n",
        "\n",
        "# Doing 2016 sqf instead because i am lazy :)))\n",
        "# columns taken from: https://github.com/adewes/fatml-pydata/blob/master/stop-and-frisk.ipynb\n",
        "\n",
        "def gen_sqf16_data():\n",
        "    #data:\n",
        "    raw_sqf16 = pd.read_csv(\"https://www1.nyc.gov/assets/nypd/downloads/excel/analysis_and_planning/stop-question-frisk/sqf-2016.csv\")\n",
        "\n",
        "    #last row is empty\n",
        "    raw_sqf16.drop(raw_sqf16.tail(1).index,inplace=True)\n",
        "\n",
        "    numeric_attr = [\n",
        "        # appearance\n",
        "        'age',      # SUSPECT'S AGE                 N\n",
        "        'weight',   # SUSPECT'S WEIGHT              N\n",
        "        # environment\n",
        "        'timestop_hour', #                          N\n",
        "        'timestop_minute', # orignally timestop, converted below into two cols N\n",
        "        'pct'       # PRECINCT OF STOP (FROM 1 TO 123), actually should be C, but hmm...\n",
        "    ]\n",
        "\n",
        "    cat_attr = [\n",
        "        # appearance\n",
        "        #'ht_feet',  # SUSPECT'S HEIGHT (FEET)       C\n",
        "        'race',     # SUSPECT'S RACE                C\n",
        "        'sex',      # SUSPECT'S SEX                 C\n",
        "        'build',    # SUSPECT'S BUILD               C\n",
        "        # environment\n",
        "        'inout',    # WAS STOP INSIDE OR OUTSIDE?   C\n",
        "        'trhsloc',  # WAS LOCATION HOUSING OR TRANSIT AUTHORITY? C\n",
        "    ]\n",
        "\n",
        "    yes_no_behavior_attribs = [\n",
        "        'ac_evasv', # EVASIVE RESPONSE TO QUESTIONING\n",
        "        'ac_assoc', # ASSOCIATING WITH KNOWN CRIMINALS\n",
        "        'cs_lkout', # SUSPECT ACTING AS A LOOKOUT\n",
        "        'cs_drgtr', # ACTIONS INDICATIVE OF A DRUG TRANSACTION\n",
        "        'cs_casng', # CASING A VICTIM OR LOCATION\n",
        "        'cs_vcrim', # VIOLENT CRIME SUSPECTED\n",
        "        'ac_cgdir', # CHANGE DIRECTION AT SIGHT OF OFFICER\n",
        "        'cs_furtv', # FURTIVE MOVEMENTS\n",
        "        'ac_stsnd', # SIGHTS OR SOUNDS OF CRIMINAL ACTIVITY\n",
        "    ]\n",
        "\n",
        "    yes_no_environment_attribs = [\n",
        "        'ac_proxm',  # PROXIMITY TO SCENE OF OFFENSE\n",
        "        'cs_other',  # OTHER\n",
        "        'ac_rept',   # REPORT BY VICTIM / WITNESS / OFFICER\n",
        "        'ac_inves',  # ONGOING INVESTIGATION\n",
        "        'ac_incid',  # AREA HAS HIGH CRIME INCIDENCE\n",
        "        'ac_time',   # TIME OF DAY FITS CRIME INCIDENCE\n",
        "    ]\n",
        "\n",
        "    yes_no_appearance_attribs = [\n",
        "        'cs_cloth', # WEARING CLOTHES COMMONLY USED IN A CRIME\n",
        "        'cs_objcs', # CARRYING SUSPICIOUS OBJECT\n",
        "        'cs_bulge', # SUSPICIOUS BULGE\n",
        "        'cs_descr', # FITS A RELEVANT DESCRIPTION\n",
        "        'rf_attir', # INAPPROPRIATE ATTIRE FOR SEASON\n",
        "    ]\n",
        "\n",
        "    yes_no_frisk_attribs = [\n",
        "        'rf_othsw', # OTHER SUSPICION OF WEAPONS    \n",
        "        'rf_knowl', # KNOWLEDGE OF SUSPECTS PRIOR CRIMINAL BEHAVIOR\n",
        "        'rf_vcact', # ACTIONS OF ENGAGING IN A VIOLENT CRIME\n",
        "        'rf_verbl', # VERBAL THREATS BY SUSPECT    \n",
        "    ]\n",
        "\n",
        "    yes_no_target_attribs = [\n",
        "        'arstmade', # WAS AN ARREST MADE?\n",
        "        'frisked',  # WAS SUSPECT FRISKED?\n",
        "        'sumissue'  # WAS A SUMMONS ISSUED?\n",
        "    ]\n",
        "\n",
        "    bin_attr = np.concatenate((yes_no_behavior_attribs,yes_no_environment_attribs,yes_no_appearance_attribs,yes_no_frisk_attribs,yes_no_target_attribs))\n",
        "\n",
        "    for attrib in bin_attr:\n",
        "        raw_sqf16[attrib] = raw_sqf16[attrib].map(dict(Y=1, N=0)).apply(np.uint8)\n",
        "\n",
        "    raw_sqf16['timestop'] = raw_sqf16['timestop'].apply(str).apply('{:0>4}'.format)\n",
        "    raw_sqf16['timestop_hour'] = raw_sqf16.timestop.apply(lambda x: datetime.strptime(x,'%H%M').hour)\n",
        "    raw_sqf16['timestop_minute'] = raw_sqf16.timestop.apply(lambda x: datetime.strptime(x,'%H%M').minute)\n",
        "    raw_sqf16.drop('timestop',axis=1,inplace=True)\n",
        "\n",
        "\n",
        "    for attrib in numeric_attr:\n",
        "      raw_sqf16[attrib] = pd.to_numeric(raw_sqf16[attrib],errors='coerce')\n",
        "\n",
        "    raw_sqf16[numeric_attr] = raw_sqf16[numeric_attr].apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=0)\n",
        "    cat_vector =  np.concatenate((np.repeat(1,len(numeric_attr)+len(bin_attr)),np.max(raw_sqf16[cat_attr].apply(lambda x: x.astype('category')).apply(lambda x: x.cat.codes))+1)) \n",
        "\n",
        "    raw_sqf16 = raw_sqf16[np.concatenate((numeric_attr,bin_attr,cat_attr))]\n",
        "    sqf16_dum = pd.get_dummies(data=raw_sqf16, columns = cat_attr)\n",
        "\n",
        "    sqf16_dum.dropna(inplace=True)\n",
        "\n",
        "    X_train_numpy = sqf16_dum.copy()\n",
        "    sqf16 = tf.convert_to_tensor(sqf16_dum.values,dtype='float32')\n",
        "\n",
        "    X_train_onehot = sqf16\n",
        "    print(X_train_onehot.shape)\n",
        "    return X_train_onehot,X_train_numpy,cat_vector\n",
        "\n",
        "\n",
        "def gen_compas_data():\n",
        "  # Used: https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n",
        "  # as base for what is important in that dataset as they do investigation into unfairness\n",
        "\n",
        "  raw_compas = pd.read_csv(\"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\")\n",
        "\n",
        "  cmp = raw_compas[['age', 'c_charge_degree', 'race', 'age_cat', 'score_text', 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid', 'two_year_recid', 'c_jail_in', 'c_jail_out']]\n",
        "  cmp = cmp.query('days_b_screening_arrest <= 30 and days_b_screening_arrest >= -30 and is_recid != -1 and c_charge_degree != \"O\" and score_text != \"N/A\"')\n",
        "  cmp = cmp.reset_index(drop=True)\n",
        "\n",
        "\n",
        "  # editing such that this will work for gan\n",
        "  # age_cat and score_text can be derived from other variables and are therefore removed\n",
        "  tmp = pd.Series(delta.total_seconds()/3600 for delta in (pd.to_datetime(cmp.c_jail_out)-pd.to_datetime(cmp.c_jail_in)))\n",
        "  cmp['length_of_stay'] = tmp\n",
        "  cmp = cmp.drop(['c_jail_out','c_jail_in','age_cat','score_text'],axis=1)\n",
        "\n",
        "  # Prepare categorical columns\n",
        "  cat_cols = ['c_charge_degree','race','sex','is_recid','two_year_recid']\n",
        "\n",
        "  # Generate vector for number of outputs for softmax\n",
        "  cat_vector = generate_gen_out_vec(cmp,cat_cols)\n",
        "\n",
        "  # Create dummy variables\n",
        "  cmp_dum = pd.get_dummies(data=cmp, columns = cat_cols)\n",
        "\n",
        "  # Rescale numeric columns\n",
        "  num_cols = len(cmp.columns)-len(cat_cols)\n",
        "  cmp_dum.iloc[:,:num_cols] = cmp_dum.iloc[:,:num_cols].apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=0) #1,0\n",
        "\n",
        "  X_train_numpy = cmp_dum.copy()\n",
        "  cmp_dum = tf.convert_to_tensor(cmp_dum.values,dtype='float32')\n",
        "\n",
        "  X_train_onehot = cmp_dum\n",
        "  print(X_train_onehot.shape)\n",
        "  return X_train_onehot,X_train_numpy,cat_vector\n",
        "\n",
        "\n",
        "# https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
        "\n",
        "def gen_schufa_data():\n",
        "  raw_schufa = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\",sep=' ',header=None)\n",
        "  \n",
        "  # Prepare categorical columns\n",
        "  cat_cols = [0,2,3,5,6,8,9,11,13,14,16,18,19,20]\n",
        "\n",
        "  # Generate vector for number of outputs for softmax\n",
        "  cat_vector = generate_gen_out_vec(raw_schufa,cat_cols)\n",
        "\n",
        "  # Create dummy variables\n",
        "  schufa_dum = pd.get_dummies(data=raw_schufa, columns = cat_cols)\n",
        "\n",
        "  # Rescale numeric columns\n",
        "  num_cols = len(raw_schufa.columns)-len(cat_cols)\n",
        "\n",
        "  schufa_dum.iloc[:,:num_cols] = schufa_dum.iloc[:,:num_cols].apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=0) #1,0\n",
        "\n",
        "  X_train_numpy = schufa_dum.copy()\n",
        "  schufa_dum = tf.convert_to_tensor(schufa_dum.values,dtype='float32')\n",
        "\n",
        "  X_train_onehot = schufa_dum\n",
        "  print(X_train_onehot.shape)\n",
        "  return X_train_onehot,X_train_numpy,cat_vector\n",
        "\n",
        "def gen_chile_data():\n",
        "  # this of course only works, if you would have access to my gdrive... \n",
        "  raw_chile = pd.read_csv('/content/drive/My Drive/unfairgan/chile dataset/ADMISION2017_Refractored_replaced.csv',sep=\";\")\n",
        "  \n",
        "  # Prepare categorical columns\n",
        "  cat_cols = ['Nationality [P008]',\n",
        "              'Gender [P009]',\n",
        "              'Civil status [P019]',\n",
        "              'Income decile [P034]',\n",
        "              'Education of father [P037]',\n",
        "              'Education of mother [P038]',\n",
        "              'Occupational status of father [P039]',\n",
        "              'Occupational status of mother [P040]',\n",
        "              'Main occupation of father [P043]',\n",
        "              'Main occupation of mother [P044]',\n",
        "              'Region [P056]',\n",
        "              'Type of high school [P077]']\n",
        "\n",
        "  # Generate vector for number of outputs for softmax\n",
        "  cat_vector = generate_gen_out_vec(raw_chile,cat_cols)\n",
        "\n",
        "  # Create dummy variables\n",
        "  chile_dum = pd.get_dummies(data=raw_chile, columns = cat_cols)\n",
        "\n",
        "  # Rescale numeric columns\n",
        "  num_cols = len(raw_chile.columns)-len(cat_cols)\n",
        "\n",
        "  chile_dum.iloc[:,:num_cols] = chile_dum.iloc[:,:num_cols].apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=0) #1,0\n",
        "\n",
        "  X_train_numpy = chile_dum.copy()\n",
        "  chile_dum = tf.convert_to_tensor(chile_dum.values,dtype='float32')\n",
        "\n",
        "  X_train_onehot = chile_dum\n",
        "  print(X_train_onehot.shape)\n",
        "  return X_train_onehot,X_train_numpy,cat_vector\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VD4cmGJR5G91",
        "colab_type": "code",
        "outputId": "a90d5009-bb7c-4669-bd53-628f706489cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dataset_name = 'chile'\n",
        "\n",
        "datasets = {'sqf':gen_sqf16_data,\n",
        "            'cmp':gen_compas_data,\n",
        "            'schufa':gen_schufa_data,\n",
        "            'chile':gen_chile_data}\n",
        "\n",
        "MODEL_DIR = 'gs://unfairgan/model_dir/' + dataset_name\n",
        "\n",
        "X_train_onehot,X_train_numpy,cat_vector = datasets[dataset_name]()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(261081, 94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0fLpPRFe638z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6efa9b72-73d0-4a9d-f0f7-0c455b92ccb6"
      },
      "cell_type": "code",
      "source": [
        "#@title Delete old model parameters to re-run\n",
        "deletion_flag = False #@param {type:\"boolean\"}\n",
        "if(deletion_flag):\n",
        "  # clear bucket to reset model\n",
        "  if(dataset_name=='sqf'):\n",
        "    !gsutil -m rm gs://unfairgan/model_dir/sqf/**\n",
        "  elif(dataset_name=='cmp'):\n",
        "    !gsutil -m rm gs://unfairgan/model_dir/cmp/**\n",
        "  elif(dataset_name=='schufa'):\n",
        "    !gsutil -m rm gs://unfairgan/model_dir/schufa/**\n",
        "  elif(dataset_name=='chile'):\n",
        "    !gsutil -m rm gs://unfairgan/model_dir/chile/**\n",
        "  else:\n",
        "    !gsutil -m rm gs://unfairgan/model_dir/**"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CommandException: 1 files/objects could not be removed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M2MVBI5i0Ub-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### model"
      ]
    },
    {
      "metadata": {
        "id": "kEHd35hJGKob",
        "colab_type": "code",
        "outputId": "a80f2391-0c8c-46b0-c091-0e7aa7f3409f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "print_corr = False\n",
        "# Hyperparameter Definition\n",
        "\n",
        "batch_size = 128 # 128 yielded pretty good results\n",
        "noise_dim = 256\n",
        "\n",
        "iterations = 100000\n",
        "learning_rate = 1e-3\n",
        "\n",
        "#wgan div\n",
        "p = 3 \n",
        "k = 2\n",
        "# Model Definition\n",
        "\n",
        "def LeakyReLU(x, alpha=0.2):\n",
        "  return tf.maximum(alpha * x, x)\n",
        "\n",
        "def generator(x,training=True):\n",
        "  with tf.variable_scope('Generator',reuse=tf.AUTO_REUSE):\n",
        "    x = tf.layers.dense(x,noise_dim,activation=LeakyReLU)\n",
        "    x = tf.layers.batch_normalization(x,momentum=0.99)\n",
        "    x = tf.layers.dense(x,512,activation=LeakyReLU)\n",
        "    x = tf.layers.batch_normalization(x,momentum=0.99)\n",
        "    x = tf.layers.dense(x,384,activation=LeakyReLU)\n",
        "    x = tf.layers.batch_normalization(x,momentum=0.99)\n",
        "    x = tf.layers.dense(x,384,activation=LeakyReLU)\n",
        "    x = tf.layers.batch_normalization(x,momentum=0.99)\n",
        "    out = []\n",
        "    for i in cat_vector:\n",
        "      if(i>1):\n",
        "        out.append(tf.layers.dense(x,i,activation=tf.contrib.sparsemax.sparsemax))#tf.nn.softmax)) # sparsemax: http://proceedings.mlr.press/v48/martins16.pdf\n",
        "      else:\n",
        "        out.append(tf.layers.dense(x,1,activation=tf.nn.sigmoid))\n",
        "    x = tf.layers.flatten(tf.concat(out,1))\n",
        "    return x\n",
        "  \n",
        "def discriminator(x,training=True):\n",
        "  with tf.variable_scope('Discriminator',reuse=tf.AUTO_REUSE):\n",
        "    x = tf.layers.dense(x,noise_dim,activation=LeakyReLU)\n",
        "    x = tf.layers.dropout(x,0.2)\n",
        "    x = tf.layers.dense(x,512,activation=LeakyReLU)\n",
        "    x = tf.layers.dropout(x,0.2)\n",
        "    x = tf.layers.dense(x,384,activation=LeakyReLU)\n",
        "    x = tf.layers.dropout(x,0.2)\n",
        "    x = tf.layers.dense(x,128,activation=LeakyReLU)\n",
        "    x = tf.layers.dropout(x,0.2)\n",
        "    x = tf.layers.dense(x,1)\n",
        "    return x\n",
        "\n",
        "# Yoinked from colab notebook above, to create a data generator class\n",
        "\n",
        "def generate_input_fn(is_training,df):\n",
        "    \"\"\"Creates input_fn depending on whether the code is training or not.\"\"\"\n",
        "    return InputFunction(is_training,df)\n",
        "\n",
        "class InputFunction(object):\n",
        "    \"\"\"Wrapper class that is passed as callable to Estimator.\"\"\"\n",
        "\n",
        "    def __init__(self, is_training,df):\n",
        "        self.is_training = is_training\n",
        "        self.df = df\n",
        "\n",
        "    def __call__(self, params):\n",
        "        \n",
        "        data = tf.data.Dataset.from_tensor_slices(self.df)\n",
        "        data = data.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=self.df.shape[0]))\n",
        "        \n",
        "        data = data.batch(batch_size, drop_remainder=True)\n",
        "        data = data.prefetch(2)\n",
        "        samples = data.make_one_shot_iterator().get_next()\n",
        "        #samples.set_shape([batch_size, 2])\n",
        "        random_noise = tf.random_normal([batch_size, noise_dim],dtype=tf.float32)\n",
        "\n",
        "        features = {\n",
        "            'real': samples,\n",
        "            'random_noise': random_noise}\n",
        "        return features\n",
        "\n",
        "def test_noise_input_fn(params):\n",
        "    np.random.seed(0)\n",
        "    noise_dataset = tf.data.Dataset.from_tensors(tf.constant(np.random.randn(params['batch_size'], noise_dim), dtype=tf.float32))\n",
        "    noise = noise_dataset.make_one_shot_iterator().get_next()\n",
        "    return {'random_noise': noise}, None\n",
        "\n",
        "def model_fn(features, mode, params):\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    random_noise = features['random_noise']\n",
        "    predictions = {'generated_samples': generator(random_noise,training=False)}\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(mode=mode,predictions=predictions)\n",
        "\n",
        "  real_data = features['real']\n",
        "  random_noise = features['random_noise']\n",
        "  \n",
        "  \n",
        "  \n",
        "  training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  fake_data = generator(random_noise,training=training)\n",
        "\n",
        "  disc_real = discriminator(real_data)\n",
        "  disc_fake = discriminator(fake_data)\n",
        "\n",
        "  gen_cost = tf.reduce_mean(disc_fake)\n",
        "  disc_cost = tf.reduce_mean(disc_real) - tf.reduce_mean(disc_fake)\n",
        "  \n",
        "  epsilon = tf.random_uniform(shape=[random_noise.get_shape().as_list()[0],1],minval=0.,maxval=1.,dtype=tf.float32)\n",
        "\n",
        "  differences = fake_data - real_data\n",
        "  interpolates = real_data + (epsilon*differences)\n",
        "  gradients = tf.gradients(discriminator(interpolates),[interpolates])[0]\n",
        "  slopes = tf.pow(tf.reduce_sum(tf.square(gradients),reduction_indices=[1]),p)\n",
        "  gradient_penalty = tf.reduce_mean(slopes)\n",
        "  disc_cost += k*gradient_penalty\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    gen_train_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0., beta2=0.9,epsilon=0.1)\n",
        "    disc_train_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0., beta2=0.9,epsilon=0.1)\n",
        "\n",
        "    g_tpu_opt = tf.contrib.tpu.CrossShardOptimizer(gen_train_opt)\n",
        "    d_tpu_opt = tf.contrib.tpu.CrossShardOptimizer(disc_train_opt)\n",
        "\n",
        "  # update op for batch_norm layer # i dont remember what it thought here :)\n",
        "\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    with tf.control_dependencies(update_ops):\n",
        "      d_step = d_tpu_opt.minimize(disc_cost, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Discriminator'))\n",
        "      g_step = g_tpu_opt.minimize(gen_cost, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Generator'))\n",
        "\n",
        "      increment_step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
        "      joint_op = tf.group([d_step, g_step, increment_step])\n",
        "      return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=gen_cost, train_op=joint_op)\n",
        "\n",
        "  elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "    def _eval_metric_fn(disc_cost,gen_cost):\n",
        "      return {'discriminator_loss': tf.metrics.mean(disc_cost),'generator_loss': tf.metrics.mean(gen_cost)}\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=tf.reduce_mean(gen_cost), eval_metrics=(_eval_metric_fn, [disc_cost, gen_cost]))\n",
        "  \n",
        "def sample_from_prob(samples):\n",
        "  # get point where values change to find first categorical column:\n",
        "  idx = np.where(cat_vector[:-1] != cat_vector[1:])[0][0]+1\n",
        "  cat_vec_short = cat_vector[idx:]\n",
        "  # loop over all categorical variables and sample from distributions\n",
        "  for i in cat_vec_short:\n",
        "    tmp = [np.random.choice(i,size=1,p=(j/np.sum(j)))[0] for j in samples.values[:,idx:i+idx]]\n",
        "    dummy = np.zeros([len(tmp),i])\n",
        "    dummy[np.arange(len(tmp)),tmp] = 1\n",
        "    samples.values[:,idx:idx+i] = dummy\n",
        "    idx += i\n",
        "  return samples\n",
        "\n",
        "\n",
        "def store_results(samples,orig):\n",
        "  samples = pd.DataFrame([s['generated_samples'][:] for s in samples])\n",
        "  samples.columns = orig.columns\n",
        "  #create directory\n",
        "  work_dir = os.path.join(os.getcwd(), 'drive/My Drive/unfairgan/'+dataset_name)\n",
        "  os.makedirs(work_dir, exist_ok=True)\n",
        "  #create filename\n",
        "  filename = datetime.now().strftime(\"data-%Y-%m-%d-%H-%M.csv\")\n",
        "  samples.to_csv(os.path.join(work_dir,filename))\n",
        "  return samples\n",
        "  \n",
        "tf.set_random_seed(1234)\n",
        "tf.logging.set_verbosity(0) # alternative: tf.logging.INFO\n",
        "config = tf.contrib.tpu.RunConfig(cluster=tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS),\n",
        "                                  #save_checkpoints_secs=None,\n",
        "                                  save_checkpoints_steps=10000,\n",
        "                                  save_summary_steps=None,\n",
        "                                  model_dir=MODEL_DIR,\n",
        "                                  tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=100)\n",
        "                                 )\n",
        "\n",
        "# I yoinked this part from the first colab notebook in above citations, i'm assuming\n",
        "# we use the cpu to predict so that we are actually on this machine to predict\n",
        "\n",
        "# TPU-based estimator used for TRAIN and EVAL\n",
        "est = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=model_fn,\n",
        "        config=config,\n",
        "        train_batch_size=batch_size,\n",
        "        eval_batch_size=batch_size)\n",
        "\n",
        "# CPU-based estimator used for PREDICT (generating images)\n",
        "cpu_est = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=model_fn,\n",
        "        use_tpu=False,\n",
        "        config=config,\n",
        "        predict_batch_size=X_train_numpy.shape[0]) # predict dataset with same size???\n",
        "\n",
        "current_step = 0\n",
        "\n",
        "steps_per_eval = 1000\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print('Starting training process ...')\n",
        "est.train(input_fn=generate_input_fn(True,X_train_onehot),max_steps=iterations)\n",
        "print('generating new dataset ...')\n",
        "pred_res = store_results(cpu_est.predict(input_fn=test_noise_input_fn),X_train_numpy)\n",
        "print(\"Total runtime: %d seconds\" %(time.time()-start_time))\n",
        "pred_res_sampled = sample_from_prob(pred_res.copy())\n",
        "if(print_corr):\n",
        "  print('generating correlation matrix ...')\n",
        "  generate_heatmap(pred_res_sampled,annot=False,output=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7fec9832d620>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7fec9832d620>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "Starting training process ...\n",
            "generating new dataset ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-4-0b3d6307518f>:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-0b3d6307518f>:21: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.batch_normalization instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-0b3d6307518f>:34: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Total runtime: 56 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zv3vTTtA_Ozh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generated set evaluation"
      ]
    },
    {
      "metadata": {
        "id": "0KrBy1ZoXwmD",
        "colab_type": "code",
        "outputId": "68004fec-4428-4413-fb26-0e348f53a071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "eval_orig = X_train_numpy.copy()\n",
        "eval_gen = pred_res_sampled.copy()\n",
        "# eval_gen_unsampled = pred_res.copy()\n",
        "\n",
        "\n",
        "\n",
        "idx = 0\n",
        "drop_cols = []\n",
        "for i in cat_vector:\n",
        "  if i>1:\n",
        "    drop_cols.append(idx)\n",
        "    idx += i\n",
        "  else:\n",
        "    idx +=1\n",
        "\n",
        "print(drop_cols)\n",
        "eval_orig.drop(eval_orig.columns[drop_cols],axis=1,inplace=True)\n",
        "eval_gen.drop(eval_gen.columns[drop_cols],axis=1,inplace=True)\n",
        "### also include the unsampled dataset if we need it\n",
        "# eval_gen_unsampled.drop(eval_gen_unsampled.columns[drop_cols],axis=1,inplace=True)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 6, 8, 12, 22, 35, 48, 55, 62, 75, 88, 90]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mpqDFYJLcPCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Writing a complete evaluation for one dataset"
      ]
    },
    {
      "metadata": {
        "id": "_1TqRi3ItKei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Aequitas / Niquitas"
      ]
    },
    {
      "metadata": {
        "id": "2Q4LVGFZtMdt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### sort such that the first group is always baseline -> i.e. set caucasian to be first group maybe?\n",
        "\n",
        "## TODO: Check if this is working correctly by using the aequitas test dataset!\n",
        "class bias_audit():\n",
        "  \n",
        "    def safe_divide(self,x,y):\n",
        "      if y == 0:\n",
        "        return 1\n",
        "      return x/y\n",
        "\n",
        "    # disparate impact\n",
        "    def disp_impact(self):\n",
        "      baseline_group = np.mean(self.y_hat[self.groups[0]])\n",
        "      return [np.divide(np.mean(self.y_hat[i]) ,baseline_group) for i in self.groups]\n",
        "\n",
        "    # demographic parity\n",
        "    def dem_parity(self):\n",
        "      baseline_group = np.mean(self.y_hat[self.groups[0]])\n",
        "      return [1- np.mean(self.y_hat[i])-baseline_group for i in self.groups]\n",
        "\n",
        "    # overall function for all rate parities:\n",
        "    def rate_parity(self,v1,v2):\n",
        "      fp = np.logical_and(self.y==v1, self.y_hat==v2)\n",
        "      fpr1 = np.sum(np.logical_and(fp, self.groups[0]))/np.sum(np.logical_and(self.y==v1, self.groups[0]))\n",
        "      return [self.safe_divide(np.sum(np.logical_and(fp, i)) / np.sum(np.logical_and(self.y==v2, i)),fpr1) for i in self.groups]\n",
        "\n",
        "    # fpr parity\n",
        "    def fpr_parity(self):\n",
        "      return self.rate_parity(0,1)\n",
        "\n",
        "    # fnr parity\n",
        "    def fnr_parity(self):\n",
        "      return self.rate_parity(1,0)\n",
        "\n",
        "    # ppv parity\n",
        "    def ppv_parity(self):\n",
        "      return self.rate_parity(1,1)\n",
        "\n",
        "    # npv parity\n",
        "    def npv_parity(self):\n",
        "      return self.rate_parity(0,0)\n",
        "\n",
        "    # acc parity\n",
        "    def acc_parity(self):\n",
        "      ac1 = np.sum(self.y[self.groups[0]]==self.y_hat[self.groups[0]]) / np.sum(self.y[self.groups[0]])\n",
        "      return [self.safe_divide(np.sum(self.y[i] == self.y_hat[i])/np.sum(self.y[i]),ac1) for i in self.groups]\n",
        "\n",
        "    def create_audit(self):\n",
        "      names = ['disparate impact','demographic parity','fpr parity','fnr parity','ppv parity','npv parity','accuracy parity']\n",
        "      return pd.DataFrame(np.column_stack((self.disp_impact(),self.dem_parity(),\n",
        "                                    self.fpr_parity(),self.fnr_parity(),\n",
        "                                    self.ppv_parity(),self.npv_parity(),\n",
        "                                    self.acc_parity())),columns=names)\n",
        "    \n",
        "    def __init__(self,y,y_hat,groups):\n",
        "      self.y = y\n",
        "      self.y_hat = y_hat\n",
        "      self.groups = groups\n",
        "      self.audit = self.create_audit()\n",
        "      \n",
        "      \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKB1baeV9sK5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation process in CV:"
      ]
    },
    {
      "metadata": {
        "id": "Yo1t-OKWdAPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CV_Eval():\n",
        "  \n",
        "  def __init__(self,X,Xg,Y,Yg,threshold,dataset_name,model_names,use_perm_imp=False):\n",
        "    \n",
        "       \n",
        "    self.X = X\n",
        "    self.Xg = Xg\n",
        "    self.Y = Y\n",
        "    self.Yg = Yg\n",
        "    self.threshold = threshold\n",
        "    self.dataset_name = dataset_name\n",
        "    self.model_names = model_names\n",
        "    self.perm_imp = use_perm_imp\n",
        "    \n",
        "    self.variable_importances = []\n",
        "    self.all_models = []\n",
        "    self.all_model_res = []\n",
        "    self.all_audits = []\n",
        "\n",
        "    self.all_cfm = []\n",
        "    self.all_acc = []\n",
        "    self.all_roc = []\n",
        "    self.all_auc = []\n",
        "  \n",
        "  \n",
        "  def calc_variable_importances(self,datasets):\n",
        "    res = {}\n",
        "    for k,v in datasets.items():\n",
        "      var_imp_model = ExtraTreesClassifier(n_estimators=100)\n",
        "      var_imp_model.fit(v[0],v[2])\n",
        "      \n",
        "      if(self.perm_imp):\n",
        "        var_imp_rf = RandomForestClassifier(n_estimators=200,n_jobs=-1)\n",
        "        var_imp_rf.fit(v[0],v[2])\n",
        "        perm = PermutationImportance(estimator=var_imp_rf,cv='prefit',n_iter=3).fit(v[1],v[3]) # we can fit to trainset and to testset\n",
        "\n",
        "        res[k] = [var_imp_model.feature_importances_,perm.feature_importances_,perm.feature_importances_std_]\n",
        "      else:\n",
        "        res[k] = [var_imp_model.feature_importances_]\n",
        "    return res\n",
        "\n",
        "  def calc_models(self,datasets):\n",
        "    model_res = {}\n",
        "    models = {}\n",
        "    \n",
        "    for k,v in datasets.items():  \n",
        "      print('glm')\n",
        "      sm_glm = GLM(v[2],add_constant(v[0]),family = Binomial()).fit()\n",
        "      sm_glm_res = sm_glm.predict(add_constant(v[1]))\n",
        "      print('lasso')\n",
        "      sk_lasso = LassoCV(cv=3,n_jobs=-1)\n",
        "      sk_lasso.fit(v[0],v[2])\n",
        "      sk_lasso_res = sk_lasso.predict(v[1])\n",
        "      \n",
        "          \n",
        "      # xgboost\n",
        "      print('xgb')\n",
        "      xgb = XGBClassifier(max_depth=3,learning_rate=.1,objective='binary:logistic',n_jobs=-1)\n",
        "      xgb.fit(v[0],v[2])\n",
        "      xgb_res = xgb.predict_proba(v[1])\n",
        "\n",
        "      # random forest\n",
        "      print('rf')\n",
        "      rf = RandomForestClassifier(n_estimators=100)\n",
        "      rf.fit(v[0].values,v[2].values)\n",
        "      rf_res = rf.predict_proba(v[1].values)\n",
        "\n",
        "\n",
        "      model_res[k] = [sm_glm_res,sk_lasso_res,xgb_res[:,1],rf_res[:,1]]\n",
        "      models[k] = [sm_glm,sk_lasso,xgb,rf]\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return models, model_res\n",
        "\n",
        "  # per class subsets for per class evaluation\n",
        "\n",
        "  def get_protected_groups(self,datasets,name):\n",
        "    grps = {}\n",
        "    if(name=='schufa'):\n",
        "      for k,v in datasets.items():\n",
        "        # Attribute 9: (qualitative) \n",
        "        # Personal status and sex \n",
        "        # A91 : male : divorced/separated \n",
        "        # A92 : female : divorced/separated/married \n",
        "        # A93 : male : single \n",
        "        # A94 : male : married/widowed \n",
        "        # A95 : female : single \n",
        "\n",
        "        schufa_f = v[1]['8_A92']==1 # | X['8_A95']==1 # second one has been removed because not generated\n",
        "        schufa_m = ~schufa_f # ~ logical not / inversion\n",
        "\n",
        "        # age numerical variable, split into 3 parts (just by age, arbitrarly chose three parts...)\n",
        "        schufa_a1 = v[1][12]<=.33\n",
        "        schufa_a3 = v[1][12]>.66\n",
        "        schufa_a2 = np.logical_not(np.logical_or(schufa_a1,schufa_a3))\n",
        "\n",
        "        # TODO we could include a all true group to compare to model\n",
        "\n",
        "        grps[k] = {'sex':{'male':schufa_m,'female':schufa_f},'age':{'age1':schufa_a1,'age2':schufa_a2,'age3':schufa_a3}}\n",
        "    elif(name=='chile'):\n",
        "      for k,v in datasets.items():\n",
        "        #\n",
        "        chile_n2 = v[1]['Nationality P008_2']==1\n",
        "        chile_n1 = ~chile_n2\n",
        "        #'Gender [P009]_2'\n",
        "        chile_g2 = v[1]['Gender P009_2']==1\n",
        "        chile_g1 = ~chile_g2\n",
        "        \n",
        "        #'Region [P056]_2'\n",
        "        chile_r2 = v[1]['Region P056_2']==1\n",
        "        chile_r1 = ~chile_r2\n",
        "        \n",
        "        #'Income decile [P034]_2', 'Income decile [P034]_3', 'Income decile [P034]_4', , \n",
        "        chile_id57 = v[1][['Income decile P034_5', 'Income decile P034_6', 'Income decile P034_7']].any(axis=1)\n",
        "        chile_id810 = v[1][['Income decile P034_8', 'Income decile P034_9', 'Income decile P034_10']].any(axis=1)\n",
        "        chile_id14 = ~ np.logical_or(chile_id57,chile_id810)\n",
        "        \n",
        "        grps[k] = {'nationality':{'n1':chile_n1,'n2':chile_n2},'gender':{'g1':chile_g1,'g2':chile_g2},'region':{'r1':chile_r1,'r2':chile_r2},'income':{'deciles 1-4':chile_id14,'deciles 5-7':chile_id57,'deciles 8-10':chile_id810}}\n",
        "      \n",
        "    return grps\n",
        "\n",
        "  def get_cfm_acc_roc(self,datasets,model_res):\n",
        "    cfms = {}\n",
        "    accs = {}\n",
        "    rocs = {}\n",
        "    aucs = {}\n",
        "\n",
        "    base_fpr = np.linspace(0,1,100)\n",
        "\n",
        "    for k,v in datasets.items():\n",
        "\n",
        "      cfm = np.empty([len(model_res[k]),2,2])\n",
        "      acc = np.empty(len(model_res[k])) \n",
        "      roc = np.empty(len(model_res[k]),dtype=object) \n",
        "      auc_ = np.empty(len(model_res[k]))\n",
        "\n",
        "      cnt = 0\n",
        "      for i in model_res[k]:\n",
        "        y_p = np.float16(i>.5)\n",
        "        cfm[cnt,:,:] = confusion_matrix(y_true=v[3],y_pred=y_p)\n",
        "        acc[cnt] = (cfm[cnt,0,0]+cfm[cnt,1,1])/v[3].shape[0]\n",
        "        fpr,tpr,_ = roc_curve(v[3],i)\n",
        "        auc_[cnt] = auc(fpr,tpr)\n",
        "        tpr = interp(base_fpr,fpr,tpr)\n",
        "        roc[cnt] = [fpr,tpr]\n",
        "        cnt +=1\n",
        "\n",
        "      cfms[k] = cfm\n",
        "      accs[k] = acc\n",
        "      rocs[k] = roc\n",
        "      aucs[k] = auc_\n",
        "\n",
        "    return cfms,accs,rocs,aucs\n",
        "\n",
        "\n",
        "  def get_niquitas(self,datasets,grps,model_res):\n",
        "    audits ={}\n",
        "    for k,v in datasets.items():\n",
        "      audits[k] = {}\n",
        "      for k1,v1 in grps[k].items():\n",
        "        audits[k][k1] = np.empty(len(model_res[k]),dtype=object)\n",
        "        prot_values = list(grps[k][k1].keys())\n",
        "        cnt = 0\n",
        "        for y_hat in model_res[k]:        \n",
        "\n",
        "          y_hat_binary = np.round(np.array(y_hat)-threshold+.5)\n",
        "          audits[k][k1][cnt] = bias_audit(v[3],y_hat_binary,list(grps[k][k1].values())).audit\n",
        "          cnt +=1\n",
        "    return audits\n",
        "  \n",
        "  def evaluate(self,n_splits):\n",
        "    self.n_splits = n_splits\n",
        "    skf = StratifiedKFold(n_splits=self.n_splits,random_state=1234)\n",
        "    cnt = 1\n",
        "    for df1,df2 in zip(skf.split(self.X,self.Y),skf.split(self.Xg,self.Yg)):\n",
        "      datasets = {'real':[self.X.iloc[df1[0]],self.X.iloc[df1[1]],\n",
        "                          self.Y[df1[0]],self.Y[df1[1]]],\n",
        "                  'generated':[self.Xg.iloc[df2[0]],self.Xg.iloc[df2[1]],\n",
        "                               self.Yg[df2[0]],self.Yg[df2[1]]]}\n",
        "      \n",
        "      print('Iteration',cnt,': calculating variable importances...')\n",
        "      self.variable_importances.append(self.calc_variable_importances(datasets))\n",
        "      \n",
        "      print('Iteration',cnt,': calculating multiple models...')\n",
        "      models,model_res = self.calc_models(datasets)\n",
        "      self.all_models.append(models)\n",
        "      self.all_model_res.append(model_res)\n",
        "      \n",
        "      \n",
        "      print('Iteration',cnt,': evaluating models...')\n",
        "      cfms,accs,rocs,aucs = self.get_cfm_acc_roc(datasets,model_res)\n",
        "      self.all_cfm.append(cfms)\n",
        "      self.all_acc.append(accs)\n",
        "      self.all_roc.append(rocs)\n",
        "      self.all_auc.append(aucs)\n",
        "      \n",
        "      print('Iteration',cnt,': developing fairness audit...')\n",
        "      self.grps = self.get_protected_groups(datasets,dataset_name) #dataset_name from beginning of this doc.\n",
        "\n",
        "      self.all_audits.append(self.get_niquitas(datasets,self.grps,model_res))\n",
        "      cnt+=1\n",
        "      gc.collect() \n",
        "      \n",
        "  def summary(self):\n",
        "    \n",
        "    # Evaluate variable importance:\n",
        "    print('\\nEvaluation of variable importance\\n -----------------------')\n",
        "    \n",
        "    print('mean extra trees real variable importance:')\n",
        "    print(np.mean([i['real'][0] for i in self.variable_importances],axis=0))\n",
        "    print('mean extra trees generated variable importance:')\n",
        "    print(np.mean([i['generated'][0] for i in self.variable_importances],axis=0))\n",
        "    print('mean extra trees variable importances spearman correlation + pvalue')\n",
        "    print(np.mean([list(stat.spearmanr(i['real'][0],i['generated'][0])) for i in self.variable_importances],axis=0))  \n",
        "\n",
        "    # I strongly believe we just drop the rf var imp and use extra trees, because it gives us the results we want :)\n",
        "    if(self.perm_imp):\n",
        "      print('mean RF Permutation Coeffs real variable importance:')\n",
        "      print(np.mean([i['real'][1] for i in self.variable_importances],axis=0))\n",
        "      print('mean RF Permutation Coeffs generated variable importance:')\n",
        "      print(np.mean([i['generated'][1] for i in self.variable_importances],axis=0))\n",
        "      print('mean RF Permutation variable importances spearman correlation + pvalue')\n",
        "      print(np.mean([list(stat.spearmanr(i['real'][1],i['generated'][1])) for i in self.variable_importances],axis=0))  \n",
        "\n",
        "    # Evaluate models:\n",
        "    \n",
        "    # print('\\nEvaluation of models\\n -----------------------')\n",
        "    \n",
        "    # print('Lasso mean intercept+coefficient:')\n",
        "    # print([i['generated'][1].intercept_ for i in all_models])\n",
        "    # print([i['generated'][1].coef_ for i in all_models])\n",
        "    # Im still not sure i can say something about average coefficients..., lets just stick to regular evaluation metrics\n",
        "\n",
        "    # Evaluate prediction\n",
        "    \n",
        "    print('\\nEvaluation of predictions using accuracy and confusion matrices with threshold:',self.threshold,'\\n -----------------------')\n",
        "    \n",
        "    print('average confusion matrices for real data using',self.model_names)\n",
        "    print(np.mean([i['real'] for i in self.all_cfm],axis=0))\n",
        "    print('average acc for real data using:',self.model_names)\n",
        "    print(np.mean([i['real'] for i in self.all_acc],axis=0))\n",
        "\n",
        "    print('average confusion matrices for generated data using',self.model_names)\n",
        "    print(np.mean([i['generated'] for i in self.all_cfm],axis=0))\n",
        "    print('average acc for generated data using:',self.model_names)\n",
        "    print(np.mean([i['generated'] for i in self.all_acc],axis=0))\n",
        "    \n",
        "    # Evaluate prediction using ROC curves:\n",
        "    \n",
        "    print('\\nEvaluation of models using ROC curves \\n -----------------------')\n",
        "    \n",
        "    base_fpr = np.linspace(0,1,100)\n",
        "    for j in range(len(self.model_names)):\n",
        "      print(self.model_names[j])\n",
        "      for k in ['real','generated']:\n",
        "        tprs = [i[k][j][1] for i in self.all_roc]\n",
        "        mean_tpr = np.mean(tprs,axis=0)\n",
        "        plt.plot(base_fpr,mean_tpr,label='Mean ROC %s data, AUC:%0.2f' % (k,np.mean([i[k][j] for i in self.all_auc])))\n",
        "        std_tpr = np.std(tprs,axis=0)\n",
        "\n",
        "        tprs_upper = np.minimum(mean_tpr+std_tpr,1)\n",
        "        tprs_lower = np.maximum(mean_tpr-std_tpr,0)\n",
        "\n",
        "        plt.fill_between(base_fpr,tprs_lower,tprs_upper,color='grey',alpha=.2)\n",
        "\n",
        "\n",
        "\n",
        "      #for i in all_roc: plt.plot(base_fpr,i['real'][j][1],alpha=.25) \n",
        "      plt.legend()  \n",
        "      plt.show()\n",
        "\n",
        "    # Aequitas Audit:\n",
        "    print('\\nmean aequitas audits: \\n---------------------')\n",
        "    \n",
        "    for k in ['real','generated']:\n",
        "      print(k,'dataset')\n",
        "      for var in self.all_audits[0]['real'].keys():\n",
        "        print('Evaluated by:',var)\n",
        "        print(np.mean([i[k][var] for i in self.all_audits]))\n",
        "\n",
        "      print('--------------------')\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NuCbB1zFq0nD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Schufa"
      ]
    },
    {
      "metadata": {
        "id": "gjZRM0GARS6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "threshold = .5\n",
        "n_splits = 5\n",
        "model_names = ['sm_glm','lasso','xgboost','random forest']\n",
        "\n",
        "#cat_vector\n",
        "schufa_indep = eval_orig.columns.tolist()\n",
        "schufa_dep = schufa_indep[-1]\n",
        "schufa_indep = schufa_indep[:-1]\n",
        "tmp = np.sum(eval_gen[schufa_indep]) > 0\n",
        "schufa_indep = tmp.index[tmp]\n",
        "\n",
        "X = eval_orig[schufa_indep]\n",
        "Y = eval_orig[schufa_dep]\n",
        "Xg = eval_gen[schufa_indep]\n",
        "Yg = eval_gen[schufa_dep]\n",
        "\n",
        "ev_schufa = CV_Eval(X,Xg,Y,Yg,threshold,dataset_name,model_names)\n",
        "ev_schufa.evaluate(n_splits=n_splits)\n",
        "ev_schufa.summary()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "idNxlCQ1ZeQj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### chile"
      ]
    },
    {
      "metadata": {
        "id": "M9TNMcsz-a6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8feecdb8-2cdf-4a69-caef-76422424463f"
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# DATA_PATH = \"/content/drive/Data\"\n",
        "# infile = open(DATA_PATH+'/notMNIST.pickle','rb')\n",
        "# best_model2 = pickle.load(infile)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cPickle\n",
            "\u001b[31m  Could not find a version that satisfies the requirement cPickle (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for cPickle\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "unIPTnuf-26G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # ev_chile\n",
        "\n",
        "#   #create directory\n",
        "#   work_dir = os.path.join(os.getcwd(), 'drive/My Drive/unfairgan/eval/'+dataset_name)\n",
        "#   os.makedirs(work_dir, exist_ok=True)\n",
        "#   #create filename\n",
        "#   filename = datetime.now().strftime(\"data-%Y-%m-%d-%H-%M.csv\")\n",
        "#   samples.to_csv(os.path.join(work_dir,filename))\n",
        "#   return samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJGY3CwdIuPx",
        "colab_type": "code",
        "outputId": "96332d1f-cd38-4790-b12c-cf159d6d57eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "gc.collect() # this is here so i can do it someitmes :)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2371"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "XnQeMKVbZfef",
        "colab_type": "code",
        "outputId": "229dfb2d-6928-41d8-83bb-a1c5efdd0545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "threshold = .5\n",
        "n_splits = 5\n",
        "model_names = ['sm_glm','lasso','xgboost','random forest']\n",
        "\n",
        "eval_gen.columns = [s.replace('[', '').replace(']','') for s in eval_gen.columns]\n",
        "eval_orig.columns = [s.replace('[', '').replace(']','') for s in eval_orig.columns]\n",
        "\n",
        "\n",
        "chile_score = ['Language test score P085', 'Math test score P086']\n",
        "\n",
        "passed = 450./850. # https://www.daad.de/medien/der-daad/analysen-studien/laendersachstand/chile_daad_sachstand.pdf\n",
        "eval_orig['passed'] = np.int8(np.mean(eval_orig[chile_score],axis=1)>=passed)\n",
        "eval_gen['passed'] = np.int8(np.mean(eval_gen[chile_score],axis=1)>=passed)\n",
        "\n",
        "chile_indep = eval_orig.columns.tolist()\n",
        "chile_dep = ['Language test score P085', 'Math test score P086','passed']\n",
        "\n",
        "[chile_indep.remove(i) for i in chile_dep]\n",
        "tmp = np.sum(eval_gen[chile_indep]) > 0\n",
        "chile_indep = tmp.index[tmp]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "chile_X = eval_orig[chile_indep]\n",
        "chile_Y = eval_orig['passed']\n",
        "chile_Xg = eval_gen[chile_indep]\n",
        "chile_Yg = eval_gen['passed']\n",
        "\n",
        "ev_chile = CV_Eval(chile_X,chile_Xg,chile_Y,chile_Yg,threshold,dataset_name,model_names)\n",
        "ev_chile.evaluate(n_splits=n_splits)\n",
        "ev_chile.summary()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 : calculating variable importances...\n",
            "Iteration 1 : calculating multiple models...\n",
            "glm\n",
            "lasso\n",
            "xgb\n",
            "rf\n",
            "glm\n",
            "lasso\n",
            "xgb\n",
            "rf\n",
            "Iteration 1 : evaluating models...\n",
            "Iteration 1 : developing fairness audit...\n",
            "Iteration 2 : calculating variable importances...\n",
            "Iteration 2 : calculating multiple models...\n",
            "glm\n",
            "lasso\n",
            "xgb\n",
            "rf\n",
            "glm\n",
            "lasso\n",
            "xgb\n",
            "rf\n",
            "Iteration 2 : evaluating models...\n",
            "Iteration 2 : developing fairness audit...\n",
            "Iteration 3 : calculating variable importances...\n",
            "Iteration 3 : calculating multiple models...\n",
            "glm\n",
            "lasso\n",
            "xgb\n",
            "rf\n",
            "glm\n",
            "lasso\n",
            "xgb\n",
            "rf\n",
            "Iteration 3 : evaluating models...\n",
            "Iteration 3 : developing fairness audit...\n",
            "Iteration 4 : calculating variable importances...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gsQVx6WTt4-N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predicting protected attributes"
      ]
    },
    {
      "metadata": {
        "id": "_n1ky5wM_ko5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = pd.DataFrame(['abc','abc'])\n",
        "ab = [a,a,a]\n",
        "pd.DataFrame(ab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64YUbfNz3VsF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CV_pred_protected():\n",
        "  \n",
        "  def __init__(self,eval_orig,eval_gen,prot_dict):\n",
        "    self.dict = prot_dict    \n",
        "    self.data_orig = eval_orig\n",
        "    self.data_gen = eval_gen\n",
        "    \n",
        "    \n",
        "    self.eval_dict = {}\n",
        "  \n",
        "  def create_var_predset(self,prot_cols,target_cols):\n",
        "    data_y_o,data_y_g = [],[]\n",
        "    \n",
        "    for i in target_cols:\n",
        "      data_y_o.append(np.int64(self.data_orig[i].any(axis=1)))\n",
        "      data_y_g.append(np.int64(self.data_gen[i].any(axis=1)))\n",
        "    \n",
        "    \n",
        "    data_x_o,data_x_g = self.data_orig.drop(prot_cols,axis=1),self.data_gen.drop(prot_cols,axis=1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return data_x_o,data_x_g,data_y_o,data_y_g\n",
        "  \n",
        "  def get_cfm_auc(self,data):\n",
        "    model1 = GLM(data[2],add_constant(data[0]),family = Binomial()).fit()\n",
        "    model2 = RandomForestClassifier(n_estimators=100).fit(data[0],data[2])\n",
        "\n",
        "    cfms = []\n",
        "    aucs = []\n",
        "\n",
        "    m1_pred = model1.predict(add_constant(data[1]))\n",
        "    m1_round = np.round(m1_pred-threshold+.5)\n",
        "\n",
        "    cfms.append(confusion_matrix(data[3],m1_round))\n",
        "    cfms.append(confusion_matrix(data[3],model2.predict(data[1])))\n",
        "    aucs.append(roc_auc_score(data[3],m1_pred))\n",
        "    aucs.append(roc_auc_score(data[3],model2.predict_proba(data[1])[:,1]))\n",
        "    return cfms,aucs\n",
        "\n",
        "  \n",
        "  def cv_pred_protected_var(self,data_x_o,data_x_g,data_y_o,data_y_g,n_splits):\n",
        "    skf = StratifiedKFold(n_splits=n_splits)\n",
        "    cfm =[]\n",
        "    auc = []\n",
        "\n",
        "    for df1,df2 in zip(skf.split(data_x_o,data_y_o),skf.split(data_x_g,data_y_g)):\n",
        "\n",
        "      data_r = [data_x_o.iloc[df1[0]],data_x_o.iloc[df1[1]],data_y_o.take(df1[0]),data_y_o.take(df1[1])]\n",
        "      data_g = [data_x_g.iloc[df2[0]],data_x_g.iloc[df2[1]],data_y_g.take(df2[0]),data_y_g.take(df2[1])]\n",
        "      data_gr= [data_g[0],data_r[1],data_g[2],data_r[3]]\n",
        "\n",
        "      for i in [data_r,data_g,data_gr]:\n",
        "        cfms, aucs = self.get_cfm_auc(i)  \n",
        "        cfm.append(cfms)\n",
        "        auc.append(aucs)\n",
        "\n",
        "    auc = np.array(auc)\n",
        "    return auc,cfm\n",
        "  \n",
        "  def evaluate(self,n_splits):\n",
        "    for k,v in self.dict.items():\n",
        "      data_x_o,data_x_g,data_y_o,data_y_g = self.create_var_predset(v[0],v[1])\n",
        "      res_auc,res_cfm = self.cv_pred_protected_var(data_x_o,data_x_g,data_y_o,data_y_g,n_splits=10)\n",
        "      \n",
        "      self.eval_dict[k] = [res_auc,res_cfm]\n",
        "      \n",
        "  # wilcoxon test for auc:\n",
        "  def wilcox_eval(self,key,model):\n",
        "    auc = self.eval_dict[key][0]\n",
        "    \n",
        "    wc_r_gr = stat.wilcoxon(auc[::3,model],auc[2::3,model])\n",
        "    wc_r_g = stat.wilcoxon(auc[::3,model],auc[1::3,model])\n",
        "    wc_g_gr = stat.wilcoxon(auc[1::3,model],auc[2::3,model])\n",
        "        \n",
        "    for wc,n in zip([wc_r_g,wc_r_gr,wc_g_gr],['wc_r_g','wc_r_gr','wc_g_gr']):\n",
        "      print(n)\n",
        "      if(wc[0]>5 and wc[1]<0.05):\n",
        "        print(wc)\n",
        "        print('H0 rejected, difference does not have a distribution with mean 0')\n",
        "      elif(wc[1]>.05):\n",
        "        print(wc)\n",
        "        print('not statistically significant')\n",
        "      else:\n",
        "        print(wc)\n",
        "        print('Cannot reject H0')\n",
        "    # return wc_1,wc_2\n",
        "    \n",
        "  def summary(self):\n",
        "    \n",
        "    print('Mean AUC+Confusion matrix for glm, rf using (real,gen,gr):')\n",
        "    models = ['glm','rf']\n",
        "    data_n = ['real','gen','train_gen_predict_real']\n",
        "    for i in range(len(models)):\n",
        "      print(models[i],'\\n---------------------------')\n",
        "      for j in range(len(data_n)):\n",
        "        print(data_n[j])\n",
        "        for k,v in self.eval_dict.items():\n",
        "          print(k)\n",
        "          mean_auc = np.mean(v[0][j::len(data_n)][i])\n",
        "          mean_cfm = np.mean(v[1][j::len(data_n)][i],axis=0)\n",
        "          print('CM:',mean_cfm)\n",
        "          print('auc:',mean_auc)\n",
        "      for key in self.eval_dict.keys(): self.wilcox_eval(key,i)\n",
        "        \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msglpppwWaSc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Schufa"
      ]
    },
    {
      "metadata": {
        "id": "JXtj-bUnYBee",
        "colab_type": "code",
        "outputId": "97acd4d5-9a3d-494e-8261-d60a5122c734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        }
      },
      "cell_type": "code",
      "source": [
        "#sex_y = eval_orig.columns  \n",
        "sexes = ['8_A92','8_A93','8_A94']\n",
        "\n",
        "# based on target sex we create the dependent variable\n",
        "target_sex = [['8_A92']]\n",
        "\n",
        "prot_dict_schufa = {'sex':[sexes,target_sex]}\n",
        "\n",
        "prot_eval_schufa = CV_pred_protected(eval_orig,eval_gen,prot_dict_schufa)\n",
        "prot_eval_schufa.evaluate(10)\n",
        "prot_eval_schufa.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean AUC+Confusion matrix for glm, rf using (real,gen,gr):\n",
            "glm \n",
            "---------------------------\n",
            "real\n",
            "sex\n",
            "CM: [[66.5  2.5]\n",
            " [23.   8. ]]\n",
            "auc: 0.7033660589060309\n",
            "gen\n",
            "sex\n",
            "CM: [[64.  7.]\n",
            " [24.  5.]]\n",
            "auc: 0.6934191355026712\n",
            "train_gen_predict_real\n",
            "sex\n",
            "CM: [[63.   6. ]\n",
            " [21.5  9.5]]\n",
            "auc: 0.7172744273024778\n",
            "wc_r_g\n",
            "not statistically significant\n",
            "wc_r_gr\n",
            "WilcoxonResult(statistic=1.0, pvalue=0.0069104298078147995)\n",
            "Cannot reject H0\n",
            "wc_g_gr\n",
            "not statistically significant\n",
            "rf \n",
            "---------------------------\n",
            "real\n",
            "sex\n",
            "CM: [[62.   7. ]\n",
            " [23.5  7.5]]\n",
            "auc: 0.6529920523609163\n",
            "gen\n",
            "sex\n",
            "CM: [[64.5  6.5]\n",
            " [19.5  9.5]]\n",
            "auc: 0.6968188440990772\n",
            "train_gen_predict_real\n",
            "sex\n",
            "CM: [[60.5  8.5]\n",
            " [21.  10. ]]\n",
            "auc: 0.7411173445535297\n",
            "wc_r_g\n",
            "WilcoxonResult(statistic=1.0, pvalue=0.0069104298078147995)\n",
            "Cannot reject H0\n",
            "wc_r_gr\n",
            "WilcoxonResult(statistic=0.0, pvalue=0.005062032126267864)\n",
            "Cannot reject H0\n",
            "wc_g_gr\n",
            "WilcoxonResult(statistic=3.0, pvalue=0.012515318690073973)\n",
            "Cannot reject H0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UqeMNrPFB1_S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# stat.anderson_ksamp([eval_orig.iloc[1],eval_gen.iloc[1]]) # i cant really find a test that would allow me to compare a n-dimensional distribution (there is one paper but no code and people say that n-dim ks test is garbage...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKqirlxi1wJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO:\n",
        "# SCHUFA ATTR 7+10 are not actually numerical but also categorical!!!\n",
        "# SQF predict multinomial -> 10 classes!\n",
        "\n",
        "#### FULL LOGIT OUTPUT mit stats package (forward selection???)\n",
        "# Variable importance (mit intercept)\n",
        "# Signifikanz\n",
        "# Koeffizienten\n",
        "\n",
        "\n",
        "#### Rückschlüsse auf original informationen (aka, predict orignal protected variables)\n",
        "# \n",
        "\n",
        "# co-integration\n",
        "# chi2 test\n",
        "\n",
        "# test for comparing coeffcients"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}